# Memories-AI .env examples

# --- Option A: OpenAI (Cloud) ---
# Use OpenAI hosted models such as gpt-5-mini
# Uncomment and set your API key:
# OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-5-mini

# --- Option B: Local gpt-oss via Responses API server (backend=ollama) ---
# Prerequisites:
# 1) Install gpt-oss server       →  pip install gpt-oss
# 2) Pull model with Ollama       →  ollama pull gpt-oss:20b
# 3) Start Responses API server   →  python -m gpt_oss.responses_api.serve --inference-backend ollama --port 8080
# 4) Configure this app to use it →  set OPENAI_BASE_URL below and MODEL (or OPENAI_MODEL)
# Notes:
# - OPENAI_API_KEY is not required for local servers; a placeholder is used internally.
# - Keep only one option (A or B) active at a time.

# OPENAI_BASE_URL=http://localhost:8080/v1
# MODEL=gpt-oss:20b

# Storage root for memories
MEMORY_ROOT=./memory
